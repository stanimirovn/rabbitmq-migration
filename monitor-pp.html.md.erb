---
title: Monitoring and KPIs for Pre&#8209;Provisioned VMware Tanzu RabbitMQ for VMs
owner: London Services
---

[//]: # (Keep changes to this page in sync with monitor.html.md.erb - especially the #rabbit-mq metrics table)

This topic explains how to monitor the health of the pre-provisioned version of the <%= vars.product_full %> service using the logs, metrics, and Key Performance Indicators (KPIs) generated by <%= vars.product_short %> component VMs.

Pre-provisioned <%= vars.product_short %> components generate many of the [same metrics](./monitor.html) as the on-demand <%= vars.product_short %> service components.

[//]: # (, but with the prefix `p-rabbitmq` instead of `p.rabbitmq`.)

See [Overview of Logging and Metrics](https://docs.pivotal.io/application-service/loggregator/data-sources.html)
for general information about logging and metrics in <%= vars.app_runtime_full %>.

## <a id="config"></a>Setting up Syslog Forwarding

Operators can enable log forwarding by configuring an external syslog endpoint for <%= vars.product_short %> component log messages. For instructions on setting up syslog forwarding, see [Configure Syslog Forwarding and Metrics Polling Interval](./install-config-pp.html#config).
If syslog forwarding is enabled, log entries with timestamps can also be found locally in `/var/log/messages`. In any case, logs are available under `/var/vcap/sys/log/`.

## <a id="format"></a>Logging Formats

With pre-provisioned <%= vars.product_short %> logging configured, three types of
component generate logs: the RabbitMQ message server nodes, the service broker,
and HAProxy. If you have multiple server or HAProxy nodes, you can identify logs
from individual nodes by their index, which corresponds to the index of the
RabbitMQ VM instances displayed in <%= vars.ops_manager %>:

* The logs for RabbitMQ server nodes follow the format <code>[job=rabbitmq-server-partition-GUID index=X]</code>
* The logs for HAProxy nodes follow the format <code>[job=rabbitmq-haproxy-partition-GUID index=X]</code>
* The logs for the RabbitMQ service broker follow the format <code>[job=rabbitmq-broker-partition-GUID index=X]</code>

RabbitMQ and HAProxy servers log at the <code>info</code> level and capture errors, warnings, and informational messages.

<%= partial vars.path_to_partials + '/rabbitmq/log-formats' %>

## <a id="metrics"></a>Metrics

Metrics are regularly-generated log messages that report measured component states. The metrics polling interval defaults to 30 seconds.
The **metrics polling interval** is a configuration option on the <%= vars.product_short %> tile (**Settings** > **RabbitMQ**). Setting this interval to -1 disables metrics. The interval setting applies to all components deployed by the tile.

Metrics are long, single lines of text that follow the format:

```mac
origin:"p-rabbitmq" eventType:ValueMetric timestamp:1441188462382091652 deployment:"cf-rabbitmq" job:"cf-rabbitmq-node" index:"0" ip:"10.244.3.46" valueMetric: < name:"/p-rabbitmq/rabbitmq/system/memory" value:1024 unit:"MB">
```

### <a id="partition-indicator"></a>Partition Indicator

A new metric has been introduced to help to identify network partitions.
Essentially it exposes how many nodes each node knows. When a node is in
partition the only node that it recognizes is itself and that is a good
indication that that node might be in a partition.

An example of that metrics is:

```mac
origin:"p-rabbitmq" eventType:ValueMetric timestamp:1441188462382091652 deployment:"cf-rabbitmq" job:"cf-rabbitmq-node" index:"0" ip:"10.244.3.46" valueMetric: < name:"/p-rabbitmq/rabbitmq/erlang/reachable_nodes" value:3 unit:"count">
```

Monitors can be created to emit alerts in case a cluster seems to be in a
partition. A metrics is emitted for each node in the cluster. For example: in a
three-node cluster a monitor can expect to have a total of 9 (nine) because each
node is expected to emit 3 (2 reachable nodes and itself). Otherwise, an alert
can be sent to the team.


## Recovering from a network partition
See [Clustering and Network Partitions](https://www.rabbitmq.com/partitions.html) in the RabbitMQ documentation to learn how to recover from a network partition.


## <a id="kpi"></a>Key Performance Indicators

Key Performance Indicators (KPIs) for <%= vars.product_short %> are metrics that operators find most useful for monitoring their RabbitMQ service to ensure smooth operation. KPIs are high-signal-value metrics that can indicate emerging issues. KPIs can be raw component metrics or _derived_ metrics generated by applying formulas to raw metrics.

VMware provides the following KPIs as general alerting and response guidance for typical <%= vars.product_short %> installations.
VMware recommends that operators continue to fine-tune the alert measures to their installation by observing historical trends.
VMware also recommends that operators expand beyond this guidance and create new, installation-specific monitoring
metrics, thresholds, and alerts based on learning from their own installations.

For a list of all <%= vars.product_short %> raw component metrics, see [Component Metrics Reference](#reference).

### <a id="heartbeats"></a>Component Heartbeats

Key <%= vars.product_short %> components periodically emit heartbeat metrics: the RabbitMQ server nodes, HAProxy nodes, and the Service Broker. The heartbeats are Boolean metrics, where <code>1</code> means the system is available, and <code>0</code> or the absence of a heartbeat metric means the service is not responding and should be investigated.

#### <a id="broker-heartbeat"></a> Service Broker Heartbeat

<table>
   <tr><th colspan="2" style="text-align: center;"><br> p-rabbitmq.service_broker.heartbeat<br><br></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>RabbitMQ Service Broker <code>is alive</code> poll, which indicates if the component is available and able to respond to requests.<br><br>

      <strong>Use</strong>: If the Service Broker does not emit heartbeats, this indicates that it is offline. The Service Broker is required to create, update, and delete service instances, which are critical for dependent tiles such as Spring Cloud Services and Spring Cloud Data Flow.
      <br><br>
      <strong>Origin</strong>: Doppler/Firehose<br>
      <strong>Type</strong>: boolean<br>
      <strong>Frequency</strong>: 30 s (default), 10 s (configurable minimum)<br>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 5 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: N/A<br>
      <strong>Red critical</strong>: &lt; 1</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>
         Check the RabbitMQ Service Broker logs for errors.
         You can find this VM by targeting your RabbitMQ deployment with BOSH and running the following command:<br>
          <code>bosh -d service-instance_GUID vms</code>
      </td>
   </tr>
</table>

#### <a id="haproxy-heartbeat"></a> HAProxy Heartbeat

<table>
   <tr><th colspan="2" style="text-align: center;"><br> p-rabbitmq.haproxy.heartbeat<br><br></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>RabbitMQ HAProxy <code>is alive</code> poll, which indicates if the component is available and
          able to respond to requests.<br><br>

      <strong>Use</strong>: If the HAProxy does not emit heartbeats, this indicates that it is offline. To be functional, service instances require HAProxy.
      <br><br>
      <strong>Origin</strong>: Doppler/Firehose<br>
      <strong>Type</strong>: boolean<br>
      <strong>Frequency</strong>: 30 s (default), 10 s (configurable minimum)<br>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 5 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: N/A<br>
      <strong>Red critical</strong>: &lt; 1</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>
         Check the RabbitMQ HAProxy logs for errors.
         You can find the VM by targeting your RabbitMQ deployment with BOSH and
         running the following command, which lists <code>HAProxy_GUID</code>:<br>
         <code>bosh -d service-instance_GUID vms</code>
      </td>
   </tr>
</table>

#### <a id="server-heartbeat"></a> Server Heartbeat

<table>
   <tr><th colspan="2" style="text-align: center;"><br> p-rabbitmq.rabbitmq.heartbeat<br><br></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>RabbitMQ Server <code>is alive</code> poll, which indicates if the component is available and
          able to respond to requests.<br><br>

      <strong>Use</strong>: If the server does not emit heartbeats, this indicates that it is offline. To be functional, service instances require RabbitMQ Server.
      <br><br>
      <strong>Origin</strong>: Doppler/Firehose<br>
      <strong>Type</strong>: boolean<br>
      <strong>Frequency</strong>: 30 s (default), 10 s (configurable minimum)<br>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 5 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: N/A<br>
      <strong>Red critical</strong>: &lt; 1</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>
         Check the RabbitMQ Server logs for errors.
         You can find the VM by targeting your RabbitMQ deployment with BOSH and
         running one of the following commands, which lists <code>rabbitmq</code>:<br>
         <code>bosh -d service-instance_GUID vms</code>
      </td>
   </tr>
</table>

### <a id="server-kpis"></a>RabbitMQ Server KPIs

The following KPIs from the RabbitMQ server component:

#### <a id="file-descriptors"></a> File Descriptors

<table>
   <tr><th colspan="2" style="text-align: center;"><br> p-rabbitmq.rabbitmq.system.file_descriptors<br><br></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>File descriptors consumed.<br><br>

      <strong>Use</strong>: If the number of file descriptors consumed becomes too large, the VM might lose the ability to perform disk I/O, which can cause data loss.
      <p class="note"><strong>Note</strong>: This assumes non-persistent messages are handled by retries or some other logic by the producers.</p>
      <strong>Origin</strong>: Doppler/Firehose<br>
      <strong>Type</strong>: count<br>
      <strong>Frequency</strong>: 30 s (default), 10 s (configurable minimum)<br>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 10 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: &gt; 250000 <br>
      <strong>Red critical</strong>: &gt; 280000</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>The default <code>ulimit</code> for <%= vars.product_short %> is 300000. If this metric is met or exceeded for an extended period of time, consider one of the following actions:
      <ul><li>Scaling the rabbit nodes in the tile <b>Resource Config</b> pane.</li>
      <li>Reduce the load on the server</li>
      </td>
   </tr>
</table>

#### <a id="erlang-processes"></a> Erlang Processes

<table>
   <tr><th colspan="2" style="text-align: center;"><br> p-rabbitmq.rabbitmq.erlang.erlang_processes<br><br></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td><a href="https://www.erlang.org/docs">Erlang</a> processes consumed by RabbitMQ, which runs on an Erlang VM.<br><br>

      <strong>Use</strong>: This is the key indicator of the processing capability of a node.
      <br><br>
      <strong>Origin</strong>: Doppler/Firehose<br>
      <strong>Type</strong>: count<br>
      <strong>Frequency</strong>: 30 s (default), 10 s (configurable minimum)<br>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 10 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: &gt; 900000 <br>
      <strong>Red critical</strong>: &gt; 950000</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>The default Erlang process limit in <%= vars.product_short %> v1.6 and later is 1,048,816. If this metric meets or exceeds the recommended thresholds for extended periods of time, consider scaling the RabbitMQ nodes in the tile <b>Resource Config</b> pane.
      </td>
   </tr>
</table>

### <a id="bosh"></a> BOSH System Health Metrics

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services/bosh_health_metrics_pcf2' %>

All BOSH-deployed components generate the system health metrics below.
These component metrics are from <%= vars.product_short %> components, and serve as KPIs for the <%= vars.product_short %> service.

#### <a id="ram"></a> RAM

<table>
   <tr><th colspan="2" style="text-align: center;"><br> system.mem.percent <br><br></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>RAM being consumed by the <code>p-rabbitmq</code> VM.<br><br>

      <strong>Use</strong>: RabbitMQ is considered to be in a good state when it has little or no messages.
              In other words, "an empty rabbit is a happy rabbit."
              Alerting on this metric can indicate that there are too few consumers or apps that read messages from the queue.
      <br><br>
      Healthmonitor reports when RabbitMQ uses more than 40% of its RAM for the past ten minutes.
      <br><br>
      <strong>Origin</strong>: BOSH HM<br>
      <strong>Type</strong>: percent<br>
      <strong>Frequency</strong>: 30 s (default), 10 s (configurable minimum)<br>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 10 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: &gt; 40 <br>
      <strong>Red critical</strong>: &gt; 50</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>Add more consumers to drain the queue as fast as possible.
      </td>
   </tr>
</table>

#### <a id="cpu"></a> CPU

<table>
   <tr><th colspan="2" style="text-align: center;"><br> system.cpu.user<br><br></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>CPU being consumed by user processes on the <code>p-rabbitmq</code> VM.<br><br>

      <strong>Use</strong>: A node that experiences context switching or high CPU usage becomes unresponsive.
      This also affects the ability of the node to report metrics.
      <br><br>
      Healthmonitor reports when RabbitMQ uses more than 40% of its CPU for the past ten minutes.
      <br><br>
      <strong>Origin</strong>: BOSH HM<br>
      <strong>Type</strong>: percent<br>
      <strong>Frequency</strong>: 30 s (default), 10 s (configurable minimum)<br>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 10 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: &gt; 60 <br>
      <strong>Red critical</strong>: &gt; 75</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td> Remember that "an empty rabbit is a happy rabbit". Add more consumers to drain the queue as fast as possible.
      </td>
   </tr>
</table>

#### <a id="ephemeral-disk"></a> Ephemeral Disk

<table>
   <tr><th colspan="2" style="text-align: center;"><br> system.disk.ephemeral.percent<br><br></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>Ephemeral Disk being consumed by the <code>p-rabbitmq</code> VM.<br><br>
      <strong>Use</strong>: If system disk fills up, there are too few consumers.
      <br><br>
      Healthmonitor reports when RabbitMQ uses more than 40% of its CPU for the past ten minutes.
      <br><br>
      <strong>Origin</strong>: BOSH HM<br>
      <strong>Type</strong>: percent<br>
      <strong>Frequency</strong>: 30 s (default), 10 s (configurable minimum)<br>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 10 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: &gt; 60 <br>
      <strong>Red critical</strong>: &gt; 75</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>Remember that "an empty rabbit is a happy rabbit". Add more consumers to drain the queue as fast as possible.
      </td>
   </tr>
</table>

#### <a id="persistent-disk"></a> Persistent Disk

<table>
   <tr><th colspan="2" style="text-align: center;"><br> system.disk.persistent.percent<br><br></th></tr>
   <tr>
      <th width="25%">Description</th>
      <td>Persistent Disk being consumed by the <code>p-rabbitmq</code> VM.<br><br>
      <strong>Use</strong>: If system disk fills up, there are too few consumers.
      <br><br>
      Healthmonitor reports when RabbitMQ uses more than 40% of its CPU for the past ten minutes.
      <br><br>
      <strong>Origin</strong>: BOSH HM<br>
      <strong>Type</strong>: percent<br>
      <strong>Frequency</strong>: 30 s (default), 10 s (configurable minimum)<br>
   </tr>
   <tr>
      <th>Recommended measurement</th>
      <td>Average over last 10 minutes</td>
   </tr>
   <tr>
      <th>Recommended alert thresholds</th>
      <td><strong>Yellow warning</strong>: &gt; 60 <br>
      <strong>Red critical</strong>: &gt; 75</td>
   </tr>
   <tr>
      <th>Recommended response</th>
      <td>Remember that "an empty rabbit is a happy rabbit". Add more consumers to drain the queue as fast as possible.
      </td>
   </tr>
</table>

## <a id="reference"></a>Component Metric Reference

<%= vars.product_short %> component VMs emit the following raw metrics. The full name of the metric follows the format: `/p-rabbitmq/COMPONENT/METRIC-NAME`

### <a id="rabbitmq-metrics"></a>RabbitMQ&nbsp; Server Metrics

<%= vars.product_short %> message server components emit the following metrics.

<table>
    <tr>
        <th>Full Name</th>
        <th>Unit</th>
        <th>Description</th>
    </tr>
    <tr>
        <td><code>/p-rabbitmq.rabbitmq.heartbeat</code></td>
        <td>boolean</td>
        <td>Indicates whether the RabbitMQ server is available and able to respond to requests</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/erlang/erlang_processes</code></td>
        <td>count</td>
        <td>The number of Erlang processes</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/system/memory</code></td>
        <td>MB</td>
        <td>The memory in MB used by the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/system/mem_alarm</code></td>
        <td>boolean</td>
        <td>Indicates if the memory alarm went off</td>
    </tr>
    <tr>
       <td><code>/p-rabbitmq/rabbitmq/system/disk_free_alarm</code></td>
       <td>boolean</td>
       <td>Indicates if the disk free alarm went off</td>
    </tr>
    <tr>
       <td><code>/p-rabbitmq/rabbitmq/system/disk_free</code></td>
       <td>MB</td>
       <td>The disk space available on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/connections/count</code></td>
        <td>count</td>
        <td>The total number of connections to the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/consumers/count</code></td>
        <td>count</td>
        <td>The total number of consumers registered in the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/messages/delivered</code></td>
        <td>count</td>
        <td>The total number of messages with the status <code>deliver_get</code> on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/messages/delivered_noack</code></td>
        <td>count</td>
        <td>The number of messages with the status <code>deliver_noack</code> on the node</td>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/messages/delivered_rate</code></td>
        <td>rate</td>
        <td>The rate per second at which messages are being delivered to consumers or clients on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/messages/published</code></td>
        <td>count</td>
        <td>The total number of messages with the status <code>publish</code> on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/messages/published_rate</code></td>
        <td>rate</td>
        <td>The rate per second at which messages are being published by the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/messages/redelivered</code></td>
        <td>count</td>
        <td>The total number of messages with the status <code>redeliver</code> on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/messages/redelivered_rate</code></td>
        <td>rate</td>
        <td>The rate per second at which messages are getting the status <code>redeliver</code> on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/messages/get_no_ack</code></td>
        <td>count</td>
        <td>The number of messages with the status <code>get_no_ack</code> on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/messages/get_no_ack_rate</code></td>
        <td>rate</td>
        <td>The rate per second at which messages get the status <code>get_no_ack</code> on the node</td>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/messages/pending</code></td>
        <td>count</td>
        <td>The number of messages with the status <code>messages_unacknowledged</code> on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/messages/depth</code></td>
        <td>count</td>
        <td>The number of messages with the status <code>messages_unacknowledged</code> or <code>messages_ready</code> on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/system/file_descriptors</code></td>
        <td>count</td>
        <td>The number of open file descriptors on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/exchanges/count</code></td>
        <td>count</td>
        <td>The total number of exchanges on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/messages/available</code></td>
        <td>count</td>
        <td>The total number of messages with the status <code>messages_ready</code> on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/queues/count</code></td>
        <td>count</td>
        <td>The number of queues on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/channels/count</code></td>
        <td>count</td>
        <td>The number of channels on the node</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/vhosts/count</code></td>
        <td>count</td>
        <td>The number of vhosts</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/queues/VHOST-NAME/QUEUE-NAME/consumers</code></td>
        <td>count</td>
        <td>The number of consumers per virtual host per queue </td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/rabbitmq/queues/VHOST-NAME/QUEUE-NAME/depth</code></td>
        <td>count</td>
        <td>The number of messages with the status <code>messages_unacknowledged</code> or <code>messages_ready</code> per virtual host per queue </td>
    </tr>
</table>


### <a id="haproxy-metrics"></a>HAProxy Metrics

<%= vars.product_short %> HAProxy components emit the following metrics.

<table>
    <tr>
        <th>Name Space</th>
        <th>Unit</th>
        <th>Description</th>
    </tr>
    <tr>
        <td><code>/p-rabbitmq.haproxy.heartbeat</code></td>
        <td>boolean</td>
        <td>Indicates whether the RabbitMQ HAProxy component is available and able to respond to requests</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/haproxy/health/connections</code></td>
        <td>count</td>
        <td>The total number of concurrent front-end connections to the server</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/haproxy/backend/qsize/amqp</code></td>
        <td>size</td>
        <td>The total size of the AMQP queue on the server</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/haproxy/backend/retries/amqp</code></td>
        <td>count</td>
        <td>The number of AMQP retries to the server</td>
    </tr>
    <tr>
        <td><code>/p-rabbitmq/haproxy/backend/ctime/amqp</code></td>
        <td>time</td>
        <td>The total time to establish the TCP AMQP connection to the server</td>
    </tr>
</table>
